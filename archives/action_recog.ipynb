{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from core.log import Logger, save_fig, save_config\n",
    "from core.data.generators import PoseGenerator\n",
    "from core.models import Encoder, Decoder, Seq2Seq\n",
    "from core.utils import save_ckpt\n",
    "from core.data.data_utils import fetch, read_3d_data, create_2d_data\n",
    "\n",
    "from pose2motion_arguments import parse_args\n",
    "from pose2motion_utils import train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_name': 'FinalTest-Original', 'dataset': 'h36m', 'keypoint_source': 'gt', 'actions': '*', 'past': 8, 'future': 16, 'time_stride': 1, 'window_stride': 4, 'batch_size': 128, 'num_workers': 4, 'encoder_ipt_dim': 32, 'encoder_opt_dim': 45, 'decoder_ipt_dim': 45, 'decoder_opt_dim': 45, 'num_recurrent_layers': 2, 'bidirectional': True, 'hid_dim': 256, 'dropout': 0.0, 'visible_devices': '0', 'device': 'cuda', 'lr': 0.002, 'lr_decay': 10000, 'lr_gamma': 0.9, 'start_epoch': 0, 'epochs': 60}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "with open('config.json') as f:\n",
    "    config = argparse.Namespace()\n",
    "    args = json.load(f)\n",
    "    d = vars(config)\n",
    "    for k, v in args.items():\n",
    "        d[k] = v\n",
    "d['batch_size'] = 128\n",
    "print(d)\n",
    "\n",
    "# os setting\n",
    "os.environ['OMP_NUM_THREAD'] = '1'\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "# a simple work-around for the dataloader multithread bug\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Using settings Namespace(actions='*', batch_size=128, bidirectional=True, dataset='h36m', decoder_ipt_dim=45, decoder_opt_dim=45, device='cuda', dropout=0.0, encoder_ipt_dim=32, encoder_opt_dim=45, epochs=60, exp_name='FinalTest-Original', future=16, hid_dim=256, keypoint_source='gt', lr=0.002, lr_decay=10000, lr_gamma=0.9, num_recurrent_layers=2, num_workers=4, past=8, start_epoch=0, time_stride=1, visible_devices='0', window_stride=4)\n",
      "==> Loading dataset... h36m\n",
      "==> Preparing data...\n",
      "==> Initializing dataloaders...\n",
      "==> Fetching subject: S1\n",
      "==> Fetching subject: S5\n",
      "==> Fetching subject: S6\n",
      "==> Fetching subject: S7\n",
      "==> Fetching subject: S8\n",
      "Generating 386568 pose sequences...\n",
      "==> Fetching subject: S9\n",
      "==> Fetching subject: S11\n",
      "Generating 67316 pose sequences...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "device = config.device\n",
    "print('==> Using settings {}'.format(config))\n",
    "\n",
    "print('==> Loading dataset...', config.dataset)\n",
    "if config.dataset == 'h36m':\n",
    "    DATASET_NAME = config.dataset.lower()\n",
    "    from core.data.h36m_dataset import Human36mDataset, TRAIN_SUBJECTS, TEST_SUBJECTS\n",
    "\n",
    "    dataset_path = Path('data', DATASET_NAME, f'data_3d_{DATASET_NAME}.npz')\n",
    "    dataset = Human36mDataset(dataset_path)\n",
    "    subjects_train = TRAIN_SUBJECTS\n",
    "    subjects_test = TEST_SUBJECTS\n",
    "else:\n",
    "    raise KeyError('Invalid dataset')\n",
    "\n",
    "print('==> Preparing data...')\n",
    "dataset = read_3d_data(dataset)\n",
    "keypoints_path = Path('data', DATASET_NAME, f'data_2d_{DATASET_NAME}_{config.keypoint_source}.npz')\n",
    "keypoints = create_2d_data(keypoints_path, dataset)\n",
    "\n",
    "print('==> Initializing dataloaders...')\n",
    "action_filter = None if config.actions == '*' else config.actions.split(',')\n",
    "# pose_2d_past_segments, pose_3d_past_segments, pose_3d_future_segments, pose_actions = data\n",
    "data = fetch(subjects_train, dataset, keypoints,\n",
    "             past=config.past, future=config.future, action_filter=action_filter,\n",
    "             window_stride=config.window_stride, time_stride=config.time_stride)\n",
    "train_loader = DataLoader(PoseGenerator(*data),\n",
    "                          batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "\n",
    "data = fetch(subjects_test, dataset, keypoints,\n",
    "             past=config.past, future=config.future, action_filter=action_filter,\n",
    "             window_stride=None, time_stride=config.time_stride)\n",
    "valid_loader = DataLoader(PoseGenerator(*data),\n",
    "                          batch_size=config.batch_size * 4, shuffle=False, num_workers=config.num_workers)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = 'ckpt_best.pth.tar'\n",
    "encoder = Encoder(config.encoder_ipt_dim, config.encoder_opt_dim,\n",
    "                  hid_dim=config.hid_dim, n_layers=config.num_recurrent_layers,\n",
    "                  bidirectional=config.bidirectional, dropout_ratio=config.dropout)\n",
    "decoder = Decoder(config.decoder_ipt_dim, config.decoder_opt_dim,\n",
    "                  hid_dim=config.hid_dim, n_layers=config.num_recurrent_layers,\n",
    "                  bidirectional=config.bidirectional, dropout_ratio=config.dropout)\n",
    "model_pos = Seq2Seq(encoder, decoder).to(device)\n",
    "model_pos.load_state_dict(torch.load(ckpt)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(predicted, labels):\n",
    "    return (predicted == labels).sum().item() / predicted.size(0)\n",
    "\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:   0 |iter:    0 | loss: 2.6873 | acc: 0.055\n",
      "ep:   0 |iter:  300 | loss: 1.5925 | acc: 0.484\n",
      "ep:   0 |iter:  600 | loss: 1.3736 | acc: 0.539\n",
      "ep:   0 |iter:  900 | loss: 1.3814 | acc: 0.555\n",
      "ep:   0 |iter: 1200 | loss: 1.4008 | acc: 0.516\n",
      "ep:   0 |iter: 1500 | loss: 1.2479 | acc: 0.625\n",
      "ep:   0 |iter: 1800 | loss: 1.0414 | acc: 0.680\n",
      "ep:   0 |iter: 2100 | loss: 1.0350 | acc: 0.625\n",
      "ep:   0 |iter: 2400 | loss: 1.0922 | acc: 0.672\n",
      "ep:   0 |iter: 2700 | loss: 0.8604 | acc: 0.742\n",
      "ep:   0 |iter: 3000 | loss: 0.9393 | acc: 0.688\n",
      "ep:   0 |iter:    0 | loss: 0.0000 | acc: 0.439\n",
      "\n",
      "ep:   1 |iter:    0 | loss: 0.9723 | acc: 0.695\n",
      "ep:   1 |iter:  300 | loss: 0.9202 | acc: 0.656\n",
      "ep:   1 |iter:  600 | loss: 0.7841 | acc: 0.773\n",
      "ep:   1 |iter:  900 | loss: 1.1049 | acc: 0.633\n",
      "ep:   1 |iter: 1200 | loss: 0.9326 | acc: 0.711\n",
      "ep:   1 |iter: 1500 | loss: 0.8259 | acc: 0.766\n",
      "ep:   1 |iter: 1800 | loss: 0.9304 | acc: 0.688\n",
      "ep:   1 |iter: 2100 | loss: 0.7925 | acc: 0.734\n",
      "ep:   1 |iter: 2400 | loss: 0.8822 | acc: 0.727\n",
      "ep:   1 |iter: 2700 | loss: 0.8315 | acc: 0.750\n",
      "ep:   1 |iter: 3000 | loss: 0.9359 | acc: 0.734\n",
      "ep:   1 |iter:    0 | loss: 0.0000 | acc: 0.464\n",
      "\n",
      "ep:   2 |iter:    0 | loss: 0.9900 | acc: 0.703\n",
      "ep:   2 |iter:  300 | loss: 0.8106 | acc: 0.773\n",
      "ep:   2 |iter:  600 | loss: 0.8902 | acc: 0.688\n",
      "ep:   2 |iter:  900 | loss: 0.8207 | acc: 0.734\n",
      "ep:   2 |iter: 1200 | loss: 0.8175 | acc: 0.719\n",
      "ep:   2 |iter: 1500 | loss: 0.7687 | acc: 0.727\n",
      "ep:   2 |iter: 1800 | loss: 0.7692 | acc: 0.742\n",
      "ep:   2 |iter: 2100 | loss: 0.8569 | acc: 0.789\n",
      "ep:   2 |iter: 2400 | loss: 0.7564 | acc: 0.773\n",
      "ep:   2 |iter: 2700 | loss: 0.9754 | acc: 0.695\n",
      "ep:   2 |iter: 3000 | loss: 0.8877 | acc: 0.773\n",
      "ep:   2 |iter:    0 | loss: 0.0000 | acc: 0.462\n",
      "\n",
      "ep:   3 |iter:    0 | loss: 0.8417 | acc: 0.773\n",
      "ep:   3 |iter:  300 | loss: 0.8516 | acc: 0.734\n",
      "ep:   3 |iter:  600 | loss: 0.8762 | acc: 0.719\n",
      "ep:   3 |iter:  900 | loss: 0.7255 | acc: 0.781\n",
      "ep:   3 |iter: 1200 | loss: 0.8399 | acc: 0.695\n",
      "ep:   3 |iter: 1500 | loss: 1.0141 | acc: 0.680\n",
      "ep:   3 |iter: 1800 | loss: 0.9366 | acc: 0.656\n",
      "ep:   3 |iter: 2100 | loss: 1.0473 | acc: 0.695\n",
      "ep:   3 |iter: 2400 | loss: 0.7967 | acc: 0.734\n",
      "ep:   3 |iter: 2700 | loss: 1.0394 | acc: 0.656\n",
      "ep:   3 |iter: 3000 | loss: 0.9088 | acc: 0.672\n",
      "ep:   3 |iter:    0 | loss: 0.0000 | acc: 0.462\n",
      "\n",
      "ep:   4 |iter:    0 | loss: 0.9521 | acc: 0.672\n",
      "ep:   4 |iter:  300 | loss: 0.7111 | acc: 0.766\n",
      "ep:   4 |iter:  600 | loss: 0.9408 | acc: 0.719\n",
      "ep:   4 |iter:  900 | loss: 0.9721 | acc: 0.688\n",
      "ep:   4 |iter: 1200 | loss: 0.7230 | acc: 0.742\n",
      "ep:   4 |iter: 1500 | loss: 1.0584 | acc: 0.664\n",
      "ep:   4 |iter: 1800 | loss: 0.9158 | acc: 0.688\n",
      "ep:   4 |iter: 2100 | loss: 0.8192 | acc: 0.742\n",
      "ep:   4 |iter: 2400 | loss: 0.8677 | acc: 0.711\n",
      "ep:   4 |iter: 2700 | loss: 0.7634 | acc: 0.742\n",
      "ep:   4 |iter: 3000 | loss: 0.8249 | acc: 0.758\n",
      "ep:   4 |iter:    0 | loss: 0.0000 | acc: 0.463\n",
      "\n",
      "ep:   5 |iter:    0 | loss: 1.0488 | acc: 0.664\n",
      "ep:   5 |iter:  300 | loss: 0.8544 | acc: 0.711\n",
      "ep:   5 |iter:  600 | loss: 0.8278 | acc: 0.766\n",
      "ep:   5 |iter:  900 | loss: 0.6459 | acc: 0.805\n",
      "ep:   5 |iter: 1200 | loss: 0.8089 | acc: 0.734\n",
      "ep:   5 |iter: 1500 | loss: 0.9647 | acc: 0.695\n",
      "ep:   5 |iter: 1800 | loss: 0.8430 | acc: 0.719\n",
      "ep:   5 |iter: 2100 | loss: 0.9062 | acc: 0.719\n",
      "ep:   5 |iter: 2400 | loss: 1.0116 | acc: 0.688\n",
      "ep:   5 |iter: 2700 | loss: 0.7533 | acc: 0.766\n",
      "ep:   5 |iter: 3000 | loss: 0.8757 | acc: 0.703\n",
      "ep:   5 |iter:    0 | loss: 0.0000 | acc: 0.464\n",
      "\n",
      "ep:   6 |iter:    0 | loss: 0.7381 | acc: 0.758\n",
      "ep:   6 |iter:  300 | loss: 0.7149 | acc: 0.797\n",
      "ep:   6 |iter:  600 | loss: 0.9626 | acc: 0.703\n",
      "ep:   6 |iter:  900 | loss: 0.8023 | acc: 0.742\n",
      "ep:   6 |iter: 1200 | loss: 0.8796 | acc: 0.727\n",
      "ep:   6 |iter: 1500 | loss: 0.9743 | acc: 0.719\n",
      "ep:   6 |iter: 1800 | loss: 0.7635 | acc: 0.789\n",
      "ep:   6 |iter: 2100 | loss: 0.9918 | acc: 0.703\n",
      "ep:   6 |iter: 2400 | loss: 0.9505 | acc: 0.688\n",
      "ep:   6 |iter: 2700 | loss: 0.9053 | acc: 0.719\n",
      "ep:   6 |iter: 3000 | loss: 0.9716 | acc: 0.688\n",
      "ep:   6 |iter:    0 | loss: 0.0000 | acc: 0.462\n",
      "\n",
      "ep:   7 |iter:    0 | loss: 0.8428 | acc: 0.734\n",
      "ep:   7 |iter:  300 | loss: 0.9799 | acc: 0.672\n",
      "ep:   7 |iter:  600 | loss: 0.9702 | acc: 0.711\n",
      "ep:   7 |iter:  900 | loss: 0.8059 | acc: 0.703\n",
      "ep:   7 |iter: 1200 | loss: 0.8188 | acc: 0.727\n",
      "ep:   7 |iter: 1500 | loss: 0.8600 | acc: 0.711\n",
      "ep:   7 |iter: 1800 | loss: 0.9055 | acc: 0.641\n",
      "ep:   7 |iter: 2100 | loss: 0.8044 | acc: 0.766\n",
      "ep:   7 |iter: 2400 | loss: 0.8881 | acc: 0.719\n",
      "ep:   7 |iter: 2700 | loss: 0.9286 | acc: 0.750\n",
      "ep:   7 |iter: 3000 | loss: 0.9423 | acc: 0.742\n",
      "ep:   7 |iter:    0 | loss: 0.0000 | acc: 0.464\n",
      "\n",
      "ep:   8 |iter:    0 | loss: 0.7480 | acc: 0.781\n",
      "ep:   8 |iter:  300 | loss: 0.9803 | acc: 0.719\n",
      "ep:   8 |iter:  600 | loss: 0.8834 | acc: 0.711\n",
      "ep:   8 |iter:  900 | loss: 1.0855 | acc: 0.648\n",
      "ep:   8 |iter: 1200 | loss: 0.7517 | acc: 0.773\n",
      "ep:   8 |iter: 1500 | loss: 0.8715 | acc: 0.742\n",
      "ep:   8 |iter: 1800 | loss: 0.8700 | acc: 0.672\n",
      "ep:   8 |iter: 2100 | loss: 0.8568 | acc: 0.711\n",
      "ep:   8 |iter: 2400 | loss: 0.8391 | acc: 0.727\n",
      "ep:   8 |iter: 2700 | loss: 0.8255 | acc: 0.742\n",
      "ep:   8 |iter: 3000 | loss: 0.9645 | acc: 0.688\n",
      "ep:   8 |iter:    0 | loss: 0.0000 | acc: 0.462\n",
      "\n",
      "ep:   9 |iter:    0 | loss: 0.8315 | acc: 0.742\n",
      "ep:   9 |iter:  300 | loss: 0.7592 | acc: 0.797\n",
      "ep:   9 |iter:  600 | loss: 0.8356 | acc: 0.742\n",
      "ep:   9 |iter:  900 | loss: 0.9093 | acc: 0.742\n",
      "ep:   9 |iter: 1200 | loss: 0.8818 | acc: 0.703\n",
      "ep:   9 |iter: 1500 | loss: 0.8493 | acc: 0.734\n",
      "ep:   9 |iter: 1800 | loss: 0.8248 | acc: 0.758\n",
      "ep:   9 |iter: 2100 | loss: 0.9643 | acc: 0.656\n",
      "ep:   9 |iter: 2400 | loss: 1.0454 | acc: 0.641\n",
      "ep:   9 |iter: 2700 | loss: 0.8418 | acc: 0.758\n",
      "ep:   9 |iter: 3000 | loss: 0.7734 | acc: 0.742\n",
      "ep:   9 |iter:    0 | loss: 0.0000 | acc: 0.464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 15)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "    \n",
    "model_act = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model_act.parameters(), lr=config.lr / 10)\n",
    "lr=config.lr / 10\n",
    "from core.utils import AverageMeter, lr_decay\n",
    "for epoch in range(n_epoch):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        loss_act = AverageMeter()\n",
    "        acc_act = AverageMeter()\n",
    "        \n",
    "        gamma = 0.9\n",
    "        lr = lr * gamma ** epoch\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        # Measure data loading time\n",
    "        pose_2d = data['pose_2d']\n",
    "        act_type = data['action_type'].to(device)\n",
    "        motion_gt = data['future_pose_3d']\n",
    "        batch, seq_len = pose_2d.size()[:2]\n",
    "        _, future_seq_len = motion_gt.size()[:2]\n",
    "        opt_dim = model_pos.encoder.opt_dim\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            # reshape, for 3d poses and motion, ignore the hip joint\n",
    "            pose_2d = pose_2d.to(device).view(batch, seq_len, -1)\n",
    "            motion_gt = motion_gt[:, :, 1:, :].to(device).view(batch, future_seq_len, -1)\n",
    "            pred = model_pos(pose_2d, motion_gt)\n",
    "            pred_pose_3d = pred['past_pose']\n",
    "            pred_motion_3d = pred['future_motion']\n",
    "            pose = pred_pose_3d.view(batch, seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "            motion = pred_motion_3d.view(batch, future_seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "        act_prediction = model_act(pose)\n",
    "        loss = criterion(act_prediction, act_type)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        loss_act.update(loss.item())\n",
    "        acc_act.update(acc(act_prediction.max(1)[1], act_type))\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print(f'ep: {epoch:3d} |iter: {i:4d} | loss: {loss_act.avg:.4f} | acc: {acc_act.avg:.3f}')\n",
    "            \n",
    "    # validation\n",
    "    model_act.eval()\n",
    "    with torch.no_grad():\n",
    "        vloss_act = AverageMeter()\n",
    "        vacc_act = AverageMeter()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            loss_act = AverageMeter()\n",
    "            acc_act = AverageMeter()\n",
    "\n",
    "            # Measure data loading time\n",
    "            pose_2d = data['pose_2d']\n",
    "            act_type = data['action_type'].to(device)\n",
    "            motion_gt = data['future_pose_3d']\n",
    "            batch, seq_len = pose_2d.size()[:2]\n",
    "            _, future_seq_len = motion_gt.size()[:2]\n",
    "            opt_dim = model_pos.encoder.opt_dim\n",
    "\n",
    "            pose_2d = pose_2d.to(device).view(batch, seq_len, -1)\n",
    "            motion_gt = motion_gt[:, :, 1:, :].to(device).view(batch, future_seq_len, -1)\n",
    "            pred = model_pos(pose_2d, motion_gt)\n",
    "            pred_pose_3d = pred['past_pose']\n",
    "            pred_motion_3d = pred['future_motion']\n",
    "            pose = pred_pose_3d.view(batch, seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "            motion = pred_motion_3d.view(batch, future_seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "            act_prediction = model_act(pose)\n",
    "            vacc_act.update(acc(act_prediction.max(1)[1], act_type))\n",
    "        print(f'ep: {epoch:3d} |iter: {0:4d} | loss: {0.0:.4f} | acc: {vacc_act.avg:.3f}\\n')\n",
    "        model_act.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:   0 |iter:    0 | loss: 2.7005 | acc: 0.109\n",
      "ep:   0 |iter:  300 | loss: 1.5574 | acc: 0.453\n",
      "ep:   0 |iter:  600 | loss: 1.3354 | acc: 0.594\n",
      "ep:   0 |iter:  900 | loss: 1.0934 | acc: 0.648\n",
      "ep:   0 |iter: 1200 | loss: 0.9302 | acc: 0.648\n",
      "ep:   0 |iter: 1500 | loss: 1.1224 | acc: 0.633\n",
      "ep:   0 |iter: 1800 | loss: 0.9864 | acc: 0.656\n",
      "ep:   0 |iter: 2100 | loss: 0.9190 | acc: 0.734\n",
      "ep:   0 |iter: 2400 | loss: 0.9786 | acc: 0.672\n",
      "ep:   0 |iter: 2700 | loss: 0.7907 | acc: 0.727\n",
      "ep:   0 |iter: 3000 | loss: 0.9159 | acc: 0.727\n",
      "ep:   0 |iter:    0 | loss: 0.0000 | acc: 0.493\n",
      "\n",
      "ep:   1 |iter:    0 | loss: 0.8410 | acc: 0.703\n",
      "ep:   1 |iter:  300 | loss: 0.7759 | acc: 0.781\n",
      "ep:   1 |iter:  600 | loss: 0.8116 | acc: 0.805\n",
      "ep:   1 |iter:  900 | loss: 0.8390 | acc: 0.719\n",
      "ep:   1 |iter: 1200 | loss: 0.8157 | acc: 0.789\n",
      "ep:   1 |iter: 1500 | loss: 0.8062 | acc: 0.750\n",
      "ep:   1 |iter: 1800 | loss: 0.9750 | acc: 0.672\n",
      "ep:   1 |iter: 2100 | loss: 0.7824 | acc: 0.742\n",
      "ep:   1 |iter: 2400 | loss: 0.8079 | acc: 0.750\n",
      "ep:   1 |iter: 2700 | loss: 0.7377 | acc: 0.781\n",
      "ep:   1 |iter: 3000 | loss: 0.9965 | acc: 0.703\n",
      "ep:   1 |iter:    0 | loss: 0.0000 | acc: 0.493\n",
      "\n",
      "ep:   2 |iter:    0 | loss: 0.7780 | acc: 0.766\n",
      "ep:   2 |iter:  300 | loss: 0.7919 | acc: 0.773\n",
      "ep:   2 |iter:  600 | loss: 0.8311 | acc: 0.734\n",
      "ep:   2 |iter:  900 | loss: 0.8583 | acc: 0.656\n",
      "ep:   2 |iter: 1200 | loss: 0.8685 | acc: 0.734\n",
      "ep:   2 |iter: 1500 | loss: 0.8164 | acc: 0.781\n",
      "ep:   2 |iter: 1800 | loss: 0.8760 | acc: 0.766\n",
      "ep:   2 |iter: 2100 | loss: 0.7993 | acc: 0.711\n",
      "ep:   2 |iter: 2400 | loss: 0.8368 | acc: 0.742\n",
      "ep:   2 |iter: 2700 | loss: 0.7709 | acc: 0.766\n",
      "ep:   2 |iter: 3000 | loss: 0.8652 | acc: 0.680\n",
      "ep:   2 |iter:    0 | loss: 0.0000 | acc: 0.494\n",
      "\n",
      "ep:   3 |iter:    0 | loss: 0.8714 | acc: 0.727\n",
      "ep:   3 |iter:  300 | loss: 0.6606 | acc: 0.773\n",
      "ep:   3 |iter:  600 | loss: 0.7697 | acc: 0.758\n",
      "ep:   3 |iter:  900 | loss: 0.9542 | acc: 0.703\n",
      "ep:   3 |iter: 1200 | loss: 0.8683 | acc: 0.742\n",
      "ep:   3 |iter: 1500 | loss: 0.7267 | acc: 0.773\n",
      "ep:   3 |iter: 1800 | loss: 0.6960 | acc: 0.766\n",
      "ep:   3 |iter: 2100 | loss: 0.9040 | acc: 0.688\n",
      "ep:   3 |iter: 2400 | loss: 0.8135 | acc: 0.727\n",
      "ep:   3 |iter: 2700 | loss: 0.7872 | acc: 0.727\n",
      "ep:   3 |iter: 3000 | loss: 0.9308 | acc: 0.758\n",
      "ep:   3 |iter:    0 | loss: 0.0000 | acc: 0.492\n",
      "\n",
      "ep:   4 |iter:    0 | loss: 0.9295 | acc: 0.719\n",
      "ep:   4 |iter:  300 | loss: 0.7374 | acc: 0.750\n",
      "ep:   4 |iter:  600 | loss: 0.8636 | acc: 0.750\n",
      "ep:   4 |iter:  900 | loss: 0.7140 | acc: 0.773\n",
      "ep:   4 |iter: 1200 | loss: 0.8184 | acc: 0.727\n",
      "ep:   4 |iter: 1500 | loss: 0.7692 | acc: 0.734\n",
      "ep:   4 |iter: 1800 | loss: 0.9824 | acc: 0.688\n",
      "ep:   4 |iter: 2100 | loss: 0.7509 | acc: 0.758\n",
      "ep:   4 |iter: 2400 | loss: 0.6002 | acc: 0.844\n",
      "ep:   4 |iter: 2700 | loss: 0.8842 | acc: 0.734\n",
      "ep:   4 |iter: 3000 | loss: 0.8038 | acc: 0.727\n",
      "ep:   4 |iter:    0 | loss: 0.0000 | acc: 0.495\n",
      "\n",
      "ep:   5 |iter:    0 | loss: 0.8733 | acc: 0.734\n",
      "ep:   5 |iter:  300 | loss: 0.7594 | acc: 0.773\n",
      "ep:   5 |iter:  600 | loss: 0.9466 | acc: 0.680\n",
      "ep:   5 |iter:  900 | loss: 0.9255 | acc: 0.703\n",
      "ep:   5 |iter: 1200 | loss: 0.9279 | acc: 0.703\n",
      "ep:   5 |iter: 1500 | loss: 0.8357 | acc: 0.688\n",
      "ep:   5 |iter: 1800 | loss: 0.8513 | acc: 0.742\n",
      "ep:   5 |iter: 2100 | loss: 0.7768 | acc: 0.789\n",
      "ep:   5 |iter: 2400 | loss: 0.6614 | acc: 0.781\n",
      "ep:   5 |iter: 2700 | loss: 0.8068 | acc: 0.773\n",
      "ep:   5 |iter: 3000 | loss: 0.6851 | acc: 0.820\n",
      "ep:   5 |iter:    0 | loss: 0.0000 | acc: 0.494\n",
      "\n",
      "ep:   6 |iter:    0 | loss: 1.0046 | acc: 0.680\n",
      "ep:   6 |iter:  300 | loss: 0.8714 | acc: 0.727\n",
      "ep:   6 |iter:  600 | loss: 0.7253 | acc: 0.758\n",
      "ep:   6 |iter:  900 | loss: 0.6668 | acc: 0.797\n",
      "ep:   6 |iter: 1200 | loss: 0.8398 | acc: 0.766\n",
      "ep:   6 |iter: 1500 | loss: 0.7885 | acc: 0.703\n",
      "ep:   6 |iter: 1800 | loss: 0.7844 | acc: 0.750\n",
      "ep:   6 |iter: 2100 | loss: 0.8336 | acc: 0.773\n",
      "ep:   6 |iter: 2400 | loss: 0.8293 | acc: 0.727\n",
      "ep:   6 |iter: 2700 | loss: 0.7036 | acc: 0.797\n",
      "ep:   6 |iter: 3000 | loss: 0.7301 | acc: 0.750\n",
      "ep:   6 |iter:    0 | loss: 0.0000 | acc: 0.495\n",
      "\n",
      "ep:   7 |iter:    0 | loss: 0.7462 | acc: 0.773\n",
      "ep:   7 |iter:  300 | loss: 0.7376 | acc: 0.742\n",
      "ep:   7 |iter:  600 | loss: 0.8370 | acc: 0.750\n",
      "ep:   7 |iter:  900 | loss: 0.7177 | acc: 0.773\n",
      "ep:   7 |iter: 1200 | loss: 0.8201 | acc: 0.734\n",
      "ep:   7 |iter: 1500 | loss: 0.6623 | acc: 0.758\n",
      "ep:   7 |iter: 1800 | loss: 0.8182 | acc: 0.750\n",
      "ep:   7 |iter: 2100 | loss: 0.9889 | acc: 0.664\n",
      "ep:   7 |iter: 2400 | loss: 0.6896 | acc: 0.789\n",
      "ep:   7 |iter: 2700 | loss: 0.7324 | acc: 0.758\n",
      "ep:   7 |iter: 3000 | loss: 0.8811 | acc: 0.750\n",
      "ep:   7 |iter:    0 | loss: 0.0000 | acc: 0.499\n",
      "\n",
      "ep:   8 |iter:    0 | loss: 0.8557 | acc: 0.719\n",
      "ep:   8 |iter:  300 | loss: 0.6637 | acc: 0.797\n",
      "ep:   8 |iter:  600 | loss: 0.8584 | acc: 0.727\n",
      "ep:   8 |iter:  900 | loss: 0.8253 | acc: 0.734\n",
      "ep:   8 |iter: 1200 | loss: 0.7155 | acc: 0.789\n",
      "ep:   8 |iter: 1500 | loss: 0.9482 | acc: 0.656\n",
      "ep:   8 |iter: 1800 | loss: 1.0121 | acc: 0.680\n",
      "ep:   8 |iter: 2100 | loss: 0.6632 | acc: 0.781\n",
      "ep:   8 |iter: 2400 | loss: 0.8670 | acc: 0.742\n",
      "ep:   8 |iter: 2700 | loss: 0.7452 | acc: 0.766\n",
      "ep:   8 |iter: 3000 | loss: 0.6049 | acc: 0.828\n",
      "ep:   8 |iter:    0 | loss: 0.0000 | acc: 0.496\n",
      "\n",
      "ep:   9 |iter:    0 | loss: 0.7954 | acc: 0.781\n",
      "ep:   9 |iter:  300 | loss: 0.7957 | acc: 0.727\n",
      "ep:   9 |iter:  600 | loss: 0.9487 | acc: 0.703\n",
      "ep:   9 |iter:  900 | loss: 0.8764 | acc: 0.719\n",
      "ep:   9 |iter: 1200 | loss: 0.8904 | acc: 0.688\n",
      "ep:   9 |iter: 1500 | loss: 0.7755 | acc: 0.773\n",
      "ep:   9 |iter: 1800 | loss: 0.8273 | acc: 0.695\n",
      "ep:   9 |iter: 2100 | loss: 0.7718 | acc: 0.773\n",
      "ep:   9 |iter: 2400 | loss: 0.7783 | acc: 0.781\n",
      "ep:   9 |iter: 2700 | loss: 0.7737 | acc: 0.742\n",
      "ep:   9 |iter: 3000 | loss: 0.8870 | acc: 0.727\n",
      "ep:   9 |iter:    0 | loss: 0.0000 | acc: 0.496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 15)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "    \n",
    "model_act = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model_act.parameters(), lr=config.lr / 10)\n",
    "lr=config.lr / 10\n",
    "from core.utils import AverageMeter, lr_decay\n",
    "for epoch in range(n_epoch):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        loss_act = AverageMeter()\n",
    "        acc_act = AverageMeter()\n",
    "\n",
    "        gamma = 0.9\n",
    "        lr = lr * gamma ** epoch\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "        # Measure data loading time\n",
    "        pose_2d = data['pose_2d']\n",
    "        act_type = data['action_type'].to(device)\n",
    "        motion_gt = data['future_pose_3d']\n",
    "        batch, seq_len = pose_2d.size()[:2]\n",
    "        _, future_seq_len = motion_gt.size()[:2]\n",
    "        opt_dim = model_pos.encoder.opt_dim\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            # reshape, for 3d poses and motion, ignore the hip joint\n",
    "            pose_2d = pose_2d.to(device).view(batch, seq_len, -1)\n",
    "            motion_gt = motion_gt[:, :, 1:, :].to(device).view(batch, future_seq_len, -1)\n",
    "            pred = model_pos(pose_2d, motion_gt)\n",
    "            pred_pose_3d = pred['past_pose']\n",
    "            pred_motion_3d = pred['future_motion']\n",
    "            pose = pred_pose_3d.view(batch, seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "            motion = pred_motion_3d.view(batch, future_seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "        act_prediction = model_act(motion)\n",
    "        loss = criterion(act_prediction, act_type)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        loss_act.update(loss.item())\n",
    "        acc_act.update(acc(act_prediction.max(1)[1], act_type))\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print(f'ep: {epoch:3d} |iter: {i:4d} | loss: {loss_act.avg:.4f} | acc: {acc_act.avg:.3f}')\n",
    "            \n",
    "    # validation\n",
    "    model_act.eval()\n",
    "    with torch.no_grad():\n",
    "        vloss_act = AverageMeter()\n",
    "        vacc_act = AverageMeter()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            loss_act = AverageMeter()\n",
    "            acc_act = AverageMeter()\n",
    "\n",
    "            # Measure data loading time\n",
    "            pose_2d = data['pose_2d']\n",
    "            act_type = data['action_type'].to(device)\n",
    "            motion_gt = data['future_pose_3d']\n",
    "            batch, seq_len = pose_2d.size()[:2]\n",
    "            _, future_seq_len = motion_gt.size()[:2]\n",
    "            opt_dim = model_pos.encoder.opt_dim\n",
    "\n",
    "            pose_2d = pose_2d.to(device).view(batch, seq_len, -1)\n",
    "            motion_gt = motion_gt[:, :, 1:, :].to(device).view(batch, future_seq_len, -1)\n",
    "            pred = model_pos(pose_2d, motion_gt)\n",
    "            pred_pose_3d = pred['past_pose']\n",
    "            pred_motion_3d = pred['future_motion']\n",
    "            pose = pred_pose_3d.view(batch, seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "            motion = pred_motion_3d.view(batch, future_seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "            act_prediction = model_act(motion)\n",
    "            vacc_act.update(acc(act_prediction.max(1)[1], act_type))\n",
    "        print(f'ep: {epoch:3d} |iter: {0:4d} | loss: {0.0:.4f} | acc: {vacc_act.avg:.3f}\\n')\n",
    "        model_act.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:   0 |iter:    0 | loss: 2.7041 | acc: 0.062\n",
      "ep:   0 |iter:  300 | loss: 1.3215 | acc: 0.586\n",
      "ep:   0 |iter:  600 | loss: 1.3254 | acc: 0.539\n",
      "ep:   0 |iter:  900 | loss: 0.9785 | acc: 0.688\n",
      "ep:   0 |iter: 1200 | loss: 0.8919 | acc: 0.703\n",
      "ep:   0 |iter: 1500 | loss: 0.9858 | acc: 0.656\n",
      "ep:   0 |iter: 1800 | loss: 1.0120 | acc: 0.695\n",
      "ep:   0 |iter: 2100 | loss: 1.0403 | acc: 0.656\n",
      "ep:   0 |iter: 2400 | loss: 0.8329 | acc: 0.734\n",
      "ep:   0 |iter: 2700 | loss: 1.0476 | acc: 0.703\n",
      "ep:   0 |iter: 3000 | loss: 0.9087 | acc: 0.727\n",
      "ep:   0 |iter:    0 | loss: 0.0000 | acc: 0.490\n",
      "\n",
      "ep:   1 |iter:    0 | loss: 0.9015 | acc: 0.688\n",
      "ep:   1 |iter:  300 | loss: 0.8773 | acc: 0.695\n",
      "ep:   1 |iter:  600 | loss: 0.7983 | acc: 0.734\n",
      "ep:   1 |iter:  900 | loss: 0.6760 | acc: 0.781\n",
      "ep:   1 |iter: 1200 | loss: 0.7801 | acc: 0.727\n",
      "ep:   1 |iter: 1500 | loss: 0.7037 | acc: 0.789\n",
      "ep:   1 |iter: 1800 | loss: 0.7362 | acc: 0.727\n",
      "ep:   1 |iter: 2100 | loss: 0.8453 | acc: 0.727\n",
      "ep:   1 |iter: 2400 | loss: 0.7980 | acc: 0.703\n",
      "ep:   1 |iter: 2700 | loss: 0.7123 | acc: 0.750\n",
      "ep:   1 |iter: 3000 | loss: 0.6542 | acc: 0.766\n",
      "ep:   1 |iter:    0 | loss: 0.0000 | acc: 0.492\n",
      "\n",
      "ep:   2 |iter:    0 | loss: 0.7751 | acc: 0.727\n",
      "ep:   2 |iter:  300 | loss: 0.8230 | acc: 0.758\n",
      "ep:   2 |iter:  600 | loss: 0.9125 | acc: 0.703\n",
      "ep:   2 |iter:  900 | loss: 0.7448 | acc: 0.766\n",
      "ep:   2 |iter: 1200 | loss: 0.7728 | acc: 0.742\n",
      "ep:   2 |iter: 1500 | loss: 0.8277 | acc: 0.711\n",
      "ep:   2 |iter: 1800 | loss: 0.7705 | acc: 0.727\n",
      "ep:   2 |iter: 2100 | loss: 0.7146 | acc: 0.750\n",
      "ep:   2 |iter: 2400 | loss: 0.7237 | acc: 0.812\n",
      "ep:   2 |iter: 2700 | loss: 0.7652 | acc: 0.742\n",
      "ep:   2 |iter: 3000 | loss: 0.6633 | acc: 0.805\n",
      "ep:   2 |iter:    0 | loss: 0.0000 | acc: 0.489\n",
      "\n",
      "ep:   3 |iter:    0 | loss: 0.8288 | acc: 0.758\n",
      "ep:   3 |iter:  300 | loss: 0.7109 | acc: 0.766\n",
      "ep:   3 |iter:  600 | loss: 0.7853 | acc: 0.766\n",
      "ep:   3 |iter:  900 | loss: 0.7094 | acc: 0.797\n",
      "ep:   3 |iter: 1200 | loss: 0.7989 | acc: 0.789\n",
      "ep:   3 |iter: 1500 | loss: 0.9199 | acc: 0.719\n",
      "ep:   3 |iter: 1800 | loss: 0.7914 | acc: 0.734\n",
      "ep:   3 |iter: 2100 | loss: 0.7151 | acc: 0.758\n",
      "ep:   3 |iter: 2400 | loss: 0.8229 | acc: 0.734\n",
      "ep:   3 |iter: 2700 | loss: 0.6648 | acc: 0.781\n",
      "ep:   3 |iter: 3000 | loss: 0.7224 | acc: 0.766\n",
      "ep:   3 |iter:    0 | loss: 0.0000 | acc: 0.491\n",
      "\n",
      "ep:   4 |iter:    0 | loss: 0.7182 | acc: 0.742\n",
      "ep:   4 |iter:  300 | loss: 0.8415 | acc: 0.742\n",
      "ep:   4 |iter:  600 | loss: 0.6621 | acc: 0.812\n",
      "ep:   4 |iter:  900 | loss: 0.7905 | acc: 0.734\n",
      "ep:   4 |iter: 1200 | loss: 0.7837 | acc: 0.750\n",
      "ep:   4 |iter: 1500 | loss: 0.8397 | acc: 0.766\n",
      "ep:   4 |iter: 1800 | loss: 0.7210 | acc: 0.773\n",
      "ep:   4 |iter: 2100 | loss: 0.6050 | acc: 0.797\n",
      "ep:   4 |iter: 2400 | loss: 0.7449 | acc: 0.773\n",
      "ep:   4 |iter: 2700 | loss: 0.8546 | acc: 0.734\n",
      "ep:   4 |iter: 3000 | loss: 0.8693 | acc: 0.734\n",
      "ep:   4 |iter:    0 | loss: 0.0000 | acc: 0.488\n",
      "\n",
      "ep:   5 |iter:    0 | loss: 0.7547 | acc: 0.734\n",
      "ep:   5 |iter:  300 | loss: 0.9332 | acc: 0.703\n",
      "ep:   5 |iter:  600 | loss: 0.8544 | acc: 0.727\n",
      "ep:   5 |iter:  900 | loss: 0.6702 | acc: 0.789\n",
      "ep:   5 |iter: 1200 | loss: 0.6720 | acc: 0.812\n",
      "ep:   5 |iter: 1500 | loss: 0.7741 | acc: 0.734\n",
      "ep:   5 |iter: 1800 | loss: 0.8107 | acc: 0.711\n",
      "ep:   5 |iter: 2100 | loss: 0.6748 | acc: 0.789\n",
      "ep:   5 |iter: 2400 | loss: 0.8591 | acc: 0.719\n",
      "ep:   5 |iter: 2700 | loss: 0.7431 | acc: 0.758\n",
      "ep:   5 |iter: 3000 | loss: 0.8184 | acc: 0.758\n",
      "ep:   5 |iter:    0 | loss: 0.0000 | acc: 0.490\n",
      "\n",
      "ep:   6 |iter:    0 | loss: 0.8075 | acc: 0.734\n",
      "ep:   6 |iter:  300 | loss: 0.7453 | acc: 0.734\n",
      "ep:   6 |iter:  600 | loss: 0.7440 | acc: 0.734\n",
      "ep:   6 |iter:  900 | loss: 0.7892 | acc: 0.719\n",
      "ep:   6 |iter: 1200 | loss: 0.7011 | acc: 0.750\n",
      "ep:   6 |iter: 1500 | loss: 0.8815 | acc: 0.727\n",
      "ep:   6 |iter: 1800 | loss: 0.8761 | acc: 0.734\n",
      "ep:   6 |iter: 2100 | loss: 0.8621 | acc: 0.734\n",
      "ep:   6 |iter: 2400 | loss: 0.6299 | acc: 0.766\n",
      "ep:   6 |iter: 2700 | loss: 0.8481 | acc: 0.688\n",
      "ep:   6 |iter: 3000 | loss: 0.7857 | acc: 0.742\n",
      "ep:   6 |iter:    0 | loss: 0.0000 | acc: 0.489\n",
      "\n",
      "ep:   7 |iter:    0 | loss: 0.7293 | acc: 0.773\n",
      "ep:   7 |iter:  300 | loss: 0.9465 | acc: 0.656\n",
      "ep:   7 |iter:  600 | loss: 0.9910 | acc: 0.711\n",
      "ep:   7 |iter:  900 | loss: 0.7066 | acc: 0.758\n",
      "ep:   7 |iter: 1200 | loss: 0.7657 | acc: 0.688\n",
      "ep:   7 |iter: 1500 | loss: 0.8754 | acc: 0.695\n",
      "ep:   7 |iter: 1800 | loss: 0.5625 | acc: 0.844\n",
      "ep:   7 |iter: 2100 | loss: 0.7253 | acc: 0.773\n",
      "ep:   7 |iter: 2400 | loss: 0.8136 | acc: 0.734\n",
      "ep:   7 |iter: 2700 | loss: 0.7531 | acc: 0.812\n",
      "ep:   7 |iter: 3000 | loss: 0.7268 | acc: 0.781\n",
      "ep:   7 |iter:    0 | loss: 0.0000 | acc: 0.491\n",
      "\n",
      "ep:   8 |iter:    0 | loss: 0.8270 | acc: 0.750\n",
      "ep:   8 |iter:  300 | loss: 0.7917 | acc: 0.742\n",
      "ep:   8 |iter:  600 | loss: 0.7388 | acc: 0.781\n",
      "ep:   8 |iter:  900 | loss: 0.7494 | acc: 0.750\n",
      "ep:   8 |iter: 1200 | loss: 0.5673 | acc: 0.844\n",
      "ep:   8 |iter: 1500 | loss: 0.8630 | acc: 0.711\n",
      "ep:   8 |iter: 1800 | loss: 0.8948 | acc: 0.680\n",
      "ep:   8 |iter: 2100 | loss: 0.6842 | acc: 0.805\n",
      "ep:   8 |iter: 2400 | loss: 0.7358 | acc: 0.781\n",
      "ep:   8 |iter: 2700 | loss: 0.7896 | acc: 0.742\n",
      "ep:   8 |iter: 3000 | loss: 0.7754 | acc: 0.773\n",
      "ep:   8 |iter:    0 | loss: 0.0000 | acc: 0.491\n",
      "\n",
      "ep:   9 |iter:    0 | loss: 0.8044 | acc: 0.758\n",
      "ep:   9 |iter:  300 | loss: 0.7917 | acc: 0.695\n",
      "ep:   9 |iter:  600 | loss: 0.8432 | acc: 0.703\n",
      "ep:   9 |iter:  900 | loss: 0.7423 | acc: 0.758\n",
      "ep:   9 |iter: 1200 | loss: 0.6788 | acc: 0.742\n",
      "ep:   9 |iter: 1500 | loss: 0.8088 | acc: 0.742\n",
      "ep:   9 |iter: 1800 | loss: 0.7545 | acc: 0.758\n",
      "ep:   9 |iter: 2100 | loss: 0.6618 | acc: 0.820\n",
      "ep:   9 |iter: 2400 | loss: 0.7266 | acc: 0.766\n",
      "ep:   9 |iter: 2700 | loss: 0.7231 | acc: 0.750\n",
      "ep:   9 |iter: 3000 | loss: 0.8463 | acc: 0.688\n",
      "ep:   9 |iter:    0 | loss: 0.0000 | acc: 0.489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(1024 + 2048, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 15)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "    \n",
    "model_act = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model_act.parameters(), lr=config.lr / 10)\n",
    "lr=config.lr / 10\n",
    "from core.utils import AverageMeter, lr_decay\n",
    "for epoch in range(n_epoch):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        loss_act = AverageMeter()\n",
    "        acc_act = AverageMeter()\n",
    "        \n",
    "        gamma = 0.9\n",
    "        lr = lr * gamma ** epoch\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        # Measure data loading time\n",
    "        pose_2d = data['pose_2d']\n",
    "        act_type = data['action_type'].to(device)\n",
    "        motion_gt = data['future_pose_3d']\n",
    "        batch, seq_len = pose_2d.size()[:2]\n",
    "        _, future_seq_len = motion_gt.size()[:2]\n",
    "        opt_dim = model_pos.encoder.opt_dim\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            # reshape, for 3d poses and motion, ignore the hip joint\n",
    "            pose_2d = pose_2d.to(device).view(batch, seq_len, -1)\n",
    "            motion_gt = motion_gt[:, :, 1:, :].to(device).view(batch, future_seq_len, -1)\n",
    "            pred = model_pos(pose_2d, motion_gt)\n",
    "            pred_pose_3d = pred['past_pose']\n",
    "            pred_motion_3d = pred['future_motion']\n",
    "            pose = pred_pose_3d.view(batch, seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "            motion = pred_motion_3d.view(batch, future_seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "        sequence = torch.cat([pose, motion], -1)\n",
    "        act_prediction = model_act(sequence)\n",
    "        loss = criterion(act_prediction, act_type)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        loss_act.update(loss.item())\n",
    "        acc_act.update(acc(act_prediction.max(1)[1], act_type))\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print(f'ep: {epoch:3d} |iter: {i:4d} | loss: {loss_act.avg:.4f} | acc: {acc_act.avg:.3f}')\n",
    "            \n",
    "    # validation\n",
    "    model_act.eval()\n",
    "    with torch.no_grad():\n",
    "        vloss_act = AverageMeter()\n",
    "        vacc_act = AverageMeter()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            loss_act = AverageMeter()\n",
    "            acc_act = AverageMeter()\n",
    "\n",
    "            # Measure data loading time\n",
    "            pose_2d = data['pose_2d']\n",
    "            act_type = data['action_type'].to(device)\n",
    "            motion_gt = data['future_pose_3d']\n",
    "            batch, seq_len = pose_2d.size()[:2]\n",
    "            _, future_seq_len = motion_gt.size()[:2]\n",
    "            opt_dim = model_pos.encoder.opt_dim\n",
    "\n",
    "            pose_2d = pose_2d.to(device).view(batch, seq_len, -1)\n",
    "            motion_gt = motion_gt[:, :, 1:, :].to(device).view(batch, future_seq_len, -1)\n",
    "            pred = model_pos(pose_2d, motion_gt)\n",
    "            pred_pose_3d = pred['past_pose']\n",
    "            pred_motion_3d = pred['future_motion']\n",
    "            pose = pred_pose_3d.view(batch, seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "            motion = pred_motion_3d.view(batch, future_seq_len, 15, 3).permute(0, 3, 2, 1)\n",
    "            sequence = torch.cat([pose, motion], -1)\n",
    "            act_prediction = model_act(sequence)\n",
    "            vacc_act.update(acc(act_prediction.max(1)[1], act_type))\n",
    "        print(f'ep: {epoch:3d} |iter: {0:4d} | loss: {0.0:.4f} | acc: {vacc_act.avg:.3f}\\n')\n",
    "        model_act.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
